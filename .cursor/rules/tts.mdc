---
description: 
globs: 
alwaysApply: true
---
<cursorrules_tts>
type: Always
description: 多模型、多语种、多风格TTS智能分发与输出目录规范，自动适配用户需求并保证输出路径统一。

***规则内容***
- 系统需自动分析用户输入的自然语言，提取语言、性别、风格、语速、情感、角色、口音等关键词：
    - 第一步：声音需求分析
      · 语言识别：自动检测配音脚本语言（中文、英文、其他）
      · 受众分析：基于课程类型识别目标受众（专业学生、科普教育、成人教育）
      · 角色定位：分析所需音色特征（性别、年龄、专业性、亲和力）
      · 情感基调：识别内容情感需求（严肃、友好、专业、生动）
      · 语速要求：根据内容复杂度确定合适语速（慢速、正常、快速）
    - 第二步：音色智能匹配
      · 中文音色库：**[MCP] mcp_DoubaoTTS_list_voice**
      · 英文音色库：**[MCP] mcp_ElevenLabs_voice_manage**
      · 备选方案：**[MCP] mcp_MiniMax_list_voices**
      · 特殊需求：根据课程专业性选择对应的专业音色
    - 第三步：音频参数优化
      · 采样率：统一32kHz高质量标准
      · 语速调节：根据内容难度和受众特点调整（0.8-1.2倍速）
      · 音量标准化：确保音频音量一致性
      · 静音处理：句间停顿优化，提升听觉体验
- 每次TTS调用前，自动检索所有TTS模型（如doubaotts、MiniMax、ElevenLabs等）当前可用的语音库，确保语音选择实时、准确。
- 模型分工与优先级：
  - 中文及方言：优先调用doubaotts（火山引擎），如无合适音色或失败，再尝试MiniMax。
  - 英文及主流外语：优先调用ElevenLabs，若无合适音色或失败，再尝试MiniMax或doubaotts。
  - 高质量多语种/特殊风格：MiniMax仅在其他模型无合适音色时作为兜底。
  - 用户指定模型/音色：严格优先按用户要求分配。
- 如首选模型/音色不可用，系统自动切换至下一个最优模型/音色，直至合成成功。
- 根据历史调用频率动态调整各模型权重，防止单一模型被过度调用。
- 如需支持新模型或新语种，需补充相应优先级、分工和输出目录规则。
</cursorrules_tts>



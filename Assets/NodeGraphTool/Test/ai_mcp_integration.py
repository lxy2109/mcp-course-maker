"""
AI-MCPé›†æˆTimelineå¤„ç†å™¨
=======================

é›†æˆAIåˆ†ç±»å™¨ä¸Unity MCPï¼Œå®ç°è‡ªåŠ¨åŒ–Timelineç”Ÿæˆ
æ”¯æŒæ‰¹é‡å¤„ç†NodeGraphï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡åŠ¨ç”»
"""

import json
import time
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from ai_timeline_classifier import AITimelineClassifier, AIProvider, AIActionResult

@dataclass
class MCPCommand:
    """MCPå‘½ä»¤ç»“æ„"""
    function_name: str
    parameters: Dict[str, Any]
    confidence: float
    node_name: str
    reasoning: str

@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœ"""
    success: bool
    processed_nodes: int
    generated_commands: List[MCPCommand]
    errors: List[str]
    processing_time: float

class AIMCPTimelineProcessor:
    """AIé©±åŠ¨çš„MCP Timelineå¤„ç†å™¨"""
    
    def __init__(self, ai_provider: AIProvider = AIProvider.MOCK, api_key: str = None):
        """
        åˆå§‹åŒ–AI-MCPå¤„ç†å™¨
        
        Args:
            ai_provider: AIæä¾›å•†
            api_key: APIå¯†é’¥
        """
        self.ai_classifier = AITimelineClassifier(provider=ai_provider, api_key=api_key)
        self.min_confidence_threshold = 0.6  # æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
        self.processed_commands = []
        
        # MCPå‡½æ•°æ˜ å°„
        self.mcp_function_mapping = {
            "camera_panorama_animation": self._generate_panorama_command,
            "camera_closeup_animation": self._generate_closeup_command,
            "camera_sweep_animation": self._generate_sweep_command,
            "rotate_around_target_animation": self._generate_orbit_command,
            "create_multipoint_animation": self._generate_multipoint_command
        }
    
    def process_nodegraph_timeline(self, nodegraph_name: str, nodegraph_path: str = "Assets/NodeGraphTool/Test") -> ProcessingResult:
        """
        å¤„ç†æ•´ä¸ªNodeGraphçš„Timeline
        
        Args:
            nodegraph_name: NodeGraphåç§°
            nodegraph_path: NodeGraphè·¯å¾„
            
        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        start_time = time.time()
        
        print(f"ğŸ¤– å¼€å§‹AIé©±åŠ¨çš„Timelineå¤„ç†")
        print(f"ç›®æ ‡NodeGraph: {nodegraph_name}")
        print("=" * 50)
        
        try:
            # 1. è·å–FlowEventNodeä¿¡æ¯ï¼ˆæ¨¡æ‹ŸMCPè°ƒç”¨ï¼‰
            flow_nodes = self._get_flow_event_nodes(nodegraph_name, nodegraph_path)
            
            if not flow_nodes:
                return ProcessingResult(
                    success=False,
                    processed_nodes=0,
                    generated_commands=[],
                    errors=["æ— æ³•è·å–FlowEventNodeä¿¡æ¯"],
                    processing_time=time.time() - start_time
                )
            
            # 2. ä½¿ç”¨AIåˆ†ææ¯ä¸ªèŠ‚ç‚¹
            generated_commands = []
            errors = []
            processed_count = 0
            
            for node_name, node_data in flow_nodes.items():
                print(f"\nğŸ” å¤„ç†èŠ‚ç‚¹: {node_name}")
                
                try:
                    commands = self._process_single_node(node_name, node_data)
                    generated_commands.extend(commands)
                    processed_count += 1
                    
                    print(f"   âœ… ç”Ÿæˆ {len(commands)} ä¸ªåŠ¨ç”»å‘½ä»¤")
                    
                except Exception as e:
                    error_msg = f"å¤„ç†èŠ‚ç‚¹ {node_name} å¤±è´¥: {str(e)}"
                    errors.append(error_msg)
                    print(f"   âŒ {error_msg}")
            
            # 3. ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
            processing_time = time.time() - start_time
            
            print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"   å¤„ç†èŠ‚ç‚¹: {processed_count}/{len(flow_nodes)}")
            print(f"   ç”Ÿæˆå‘½ä»¤: {len(generated_commands)}")
            print(f"   é”™è¯¯æ•°é‡: {len(errors)}")
            print(f"   å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")
            
            return ProcessingResult(
                success=len(errors) == 0,
                processed_nodes=processed_count,
                generated_commands=generated_commands,
                errors=errors,
                processing_time=processing_time
            )
            
        except Exception as e:
            return ProcessingResult(
                success=False,
                processed_nodes=0,
                generated_commands=[],
                errors=[f"å¤„ç†å¤±è´¥: {str(e)}"],
                processing_time=time.time() - start_time
            )
    
    def _get_flow_event_nodes(self, nodegraph_name: str, nodegraph_path: str) -> Dict[str, Dict]:
        """
        è·å–FlowEventNodeä¿¡æ¯ï¼ˆæ¨¡æ‹ŸMCPè°ƒç”¨ï¼‰
        åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„MCPå‡½æ•°
        """
        # æ¨¡æ‹ŸèŠ‚ç‚¹æ•°æ®ï¼ˆåœ¨å®é™…ç¯å¢ƒä¸­ä¼šè°ƒç”¨MCPï¼‰
        mock_nodes = {
            "äº†è§£å®éªŒç›®çš„åŠæ„ä¹‰": {
                "é•œå¤´timelineåç§°": "è¯¾ç¨‹ä»‹ç»_é•œå¤´",
                "é•œå¤´timelineå†…å®¹": "é•œå¤´ç¯è§†æ•´ä¸ªå®éªŒå°ï¼Œå±•ç¤ºæ‰€æœ‰å®éªŒè®¾å¤‡",
                "ç‰©ä½“timelineåç§°": "-",
                "ç‰©ä½“timelineå†…å®¹": "-"
            },
            "æ£€æŸ¥ä»ªå™¨å¤–è§‚": {
                "é•œå¤´timelineåç§°": "æ£€æŸ¥å¤–è§‚_é•œå¤´", 
                "é•œå¤´timelineå†…å®¹": "é•œå¤´èšç„¦åˆ°ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ªè¿›è¡Œç‰¹å†™è§‚å¯Ÿ",
                "ç‰©ä½“timelineåç§°": "-",
                "ç‰©ä½“timelineå†…å®¹": "-"
            },
            "è¿æ¥ä»ªå™¨ç”µæº": {
                "é•œå¤´timelineåç§°": "è¿æ¥ç”µæº_é•œå¤´",
                "é•œå¤´timelineå†…å®¹": "é•œå¤´è·Ÿéšç”µæºçº¿çš„ç§»åŠ¨è¿‡ç¨‹",
                "ç‰©ä½“timelineåç§°": "è¿æ¥ç”µæº_ç”µæºçº¿",
                "ç‰©ä½“timelineå†…å®¹": "ç”µæºçº¿å¹³ç§»è‡³æ’æ’ç”µæºå£å¤„å¹¶æ’å…¥"
            },
            "æŒ‰ä¸‹ç”µæºæŒ‰é’®": {
                "é•œå¤´timelineåç§°": "æŒ‰ä¸‹æŒ‰é’®_é•œå¤´",
                "é•œå¤´timelineå†…å®¹": "é•œå¤´èšç„¦åˆ°ç”µæºæŒ‰é’®éƒ¨ä½è¿›è¡Œç‰¹å†™",
                "ç‰©ä½“timelineåç§°": "æŒ‰ä¸‹æŒ‰é’®_æŒ‰é’®",
                "ç‰©ä½“timelineå†…å®¹": "ç”µæºæŒ‰é’®å‘ä¸‹æŒ‰å‹ï¼Œç„¶åå¼¹å›"
            },
            "è®¾ç½®æ³¢é•¿å€¼": {
                "é•œå¤´timelineåç§°": "è®¾ç½®æ³¢é•¿_é•œå¤´",
                "é•œå¤´timelineå†…å®¹": "é•œå¤´ä»æ­£é¢è§‚å¯Ÿæ˜¾ç¤ºå±å’Œæ§åˆ¶é¢æ¿",
                "ç‰©ä½“timelineåç§°": "è®¾ç½®æ³¢é•¿_æ—‹é’®",
                "ç‰©ä½“timelineå†…å®¹": "æ³¢é•¿è°ƒèŠ‚æ—‹é’®é¡ºæ—¶é’ˆæ—‹è½¬90åº¦"
            }
        }
        
        print(f"ğŸ“š æ¨¡æ‹Ÿè·å–åˆ° {len(mock_nodes)} ä¸ªFlowEventNode")
        return mock_nodes
    
    def _process_single_node(self, node_name: str, node_data: Dict) -> List[MCPCommand]:
        """å¤„ç†å•ä¸ªèŠ‚ç‚¹çš„Timelineä¿¡æ¯"""
        commands = []
        
        # å¤„ç†é•œå¤´Timeline
        camera_timeline_content = node_data.get("é•œå¤´timelineå†…å®¹", "")
        if camera_timeline_content and camera_timeline_content.strip() not in ["-", "æ— ", ""]:
            
            print(f"   ğŸ¥ åˆ†æé•œå¤´åŠ¨ä½œ: {camera_timeline_content}")
            
            ai_result = self.ai_classifier.classify_timeline_action(
                camera_timeline_content, "camera"
            )
            
            if ai_result.confidence >= self.min_confidence_threshold:
                command = self._generate_mcp_command(ai_result, node_name, "camera")
                if command:
                    commands.append(command)
                    print(f"      âœ… ç”Ÿæˆé•œå¤´å‘½ä»¤ (ç½®ä¿¡åº¦: {ai_result.confidence:.2f})")
            else:
                print(f"      âš ï¸ é•œå¤´åŠ¨ä½œç½®ä¿¡åº¦è¿‡ä½: {ai_result.confidence:.2f}")
        
        # å¤„ç†ç‰©ä½“Timeline
        object_timeline_content = node_data.get("ç‰©ä½“timelineå†…å®¹", "")
        if object_timeline_content and object_timeline_content.strip() not in ["-", "æ— ", ""]:
            
            print(f"   ğŸ¯ åˆ†æç‰©ä½“åŠ¨ä½œ: {object_timeline_content}")
            
            ai_result = self.ai_classifier.classify_timeline_action(
                object_timeline_content, "object"
            )
            
            if ai_result.confidence >= self.min_confidence_threshold:
                command = self._generate_mcp_command(ai_result, node_name, "object")
                if command:
                    commands.append(command)
                    print(f"      âœ… ç”Ÿæˆç‰©ä½“å‘½ä»¤ (ç½®ä¿¡åº¦: {ai_result.confidence:.2f})")
            else:
                print(f"      âš ï¸ ç‰©ä½“åŠ¨ä½œç½®ä¿¡åº¦è¿‡ä½: {ai_result.confidence:.2f}")
        
        return commands
    
    def _generate_mcp_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Optional[MCPCommand]:
        """æ ¹æ®AIåˆ†æç»“æœç”ŸæˆMCPå‘½ä»¤"""
        
        function_name = ai_result.mcp_function
        if function_name not in self.mcp_function_mapping:
            print(f"      âŒ ä¸æ”¯æŒçš„MCPå‡½æ•°: {function_name}")
            return None
        
        # è°ƒç”¨å¯¹åº”çš„å‘½ä»¤ç”Ÿæˆå™¨
        generator = self.mcp_function_mapping[function_name]
        parameters = generator(ai_result, node_name, timeline_type)
        
        return MCPCommand(
            function_name=function_name,
            parameters=parameters,
            confidence=ai_result.confidence,
            node_name=node_name,
            reasoning=ai_result.reasoning
        )
    
    def _generate_panorama_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆå…¨æ™¯åŠ¨ç”»å‘½ä»¤å‚æ•°"""
        base_params = ai_result.parameters
        
        return {
            "camera_name": base_params.get("camera_name", "Main Camera"),
            "pitch_angle": base_params.get("pitch_angle", -20),
            "duration": base_params.get("duration", 10),
            "steps": base_params.get("steps", 24),
            "timeline_asset_name": f"{node_name}_panorama",
            "move_to_start": True,
            "return_to_origin": False
        }
    
    def _generate_closeup_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆç‰¹å†™åŠ¨ç”»å‘½ä»¤å‚æ•°"""
        base_params = ai_result.parameters
        
        # ä»AIç»“æœä¸­æå–ç›®æ ‡ç‰©ä½“
        target_object = base_params.get("target_object_name")
        if not target_object:
            # å°è¯•ä»AIçš„extracted_objectsä¸­è·å–
            extracted_objects = base_params.get("extracted_objects", [])
            if extracted_objects:
                target_object = extracted_objects[0]
            else:
                target_object = "ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ª"  # é»˜è®¤ç›®æ ‡
        
        return {
            "camera_name": base_params.get("camera_name", "Main Camera"),
            "target_object_name": target_object,
            "closeup_distance": base_params.get("closeup_distance", 5),
            "pitch_angle": base_params.get("pitch_angle", 10),
            "duration": base_params.get("duration", 8),
            "horizontal_angle": base_params.get("horizontal_angle", 60),
            "move_speed": base_params.get("move_speed", 5),
            "timeline_asset_name": f"{node_name}_closeup",
            "move_to_start": True,
            "return_to_origin": False
        }
    
    def _generate_sweep_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰«è§†åŠ¨ç”»å‘½ä»¤å‚æ•°"""
        base_params = ai_result.parameters
        
        return {
            "camera_name": base_params.get("camera_name", "Main Camera"),
            "pitch_angle": base_params.get("pitch_angle", 0),
            "sweep_angle": base_params.get("sweep_angle", 45),
            "duration": base_params.get("duration", 8),
            "steps": base_params.get("steps", 18),
            "timeline_asset_name": f"{node_name}_sweep",
            "move_to_start": True,
            "return_to_origin": False
        }
    
    def _generate_orbit_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆç¯ç»•åŠ¨ç”»å‘½ä»¤å‚æ•°"""
        base_params = ai_result.parameters
        
        if timeline_type == "camera":
            moving_object = base_params.get("camera_name", "Main Camera")
        else:
            moving_object = base_params.get("name", "unknown_object")
        
        return {
            "moving_object_name": moving_object,
            "target_object_name": base_params.get("target_object_name", "ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ª"),
            "radius": base_params.get("radius", 8),
            "height": base_params.get("height", 2),
            "duration": base_params.get("duration", 12),
            "look_at_target": timeline_type == "camera",
            "timeline_asset_name": f"{node_name}_orbit",
            "move_to_start": True,
            "return_to_origin": False
        }
    
    def _generate_multipoint_command(self, ai_result: AIActionResult, node_name: str, timeline_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆå¤šç‚¹åŠ¨ç”»å‘½ä»¤å‚æ•°"""
        base_params = ai_result.parameters
        
        # ç¡®å®šå¯¹è±¡åç§°
        if timeline_type == "camera":
            object_name = base_params.get("camera_name", "Main Camera")
        else:
            object_name = base_params.get("name", "unknown_object")
        
        # ç”Ÿæˆè·¯å¾„ç‚¹
        points = base_params.get("points", [])
        if not points:
            # åˆ›å»ºé»˜è®¤è·¯å¾„ç‚¹
            if base_params.get("include_rotation", False):
                # æŒ‰é’®æŒ‰å‹åŠ¨ä½œ
                points = [
                    {"position": {"x": 0, "y": 0, "z": 0}, "rotation": {"x": 0, "y": 0, "z": 0}},
                    {"position": {"x": 0, "y": -0.1, "z": 0}, "rotation": {"x": 0, "y": 0, "z": 0}},
                    {"position": {"x": 0, "y": 0, "z": 0}, "rotation": {"x": 0, "y": 0, "z": 0}}
                ]
            else:
                # ç§»åŠ¨åŠ¨ä½œ
                points = [
                    {"position": {"x": 0, "y": 0, "z": 0}},
                    {"position": {"x": 3, "y": 0, "z": 2}},
                    {"position": {"x": 0, "y": 0, "z": 0}}
                ]
        
        return {
            "name": object_name,
            "points": points,
            "duration": base_params.get("duration", 5),
            "path_type": base_params.get("path_type", "linear"),
            "include_rotation": base_params.get("include_rotation", False),
            "timeline_asset_name": f"{node_name}_multipoint",
            "move_to_start": True,
            "return_to_origin": False
        }
    
    def execute_commands(self, commands: List[MCPCommand], dry_run: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œç”Ÿæˆçš„MCPå‘½ä»¤
        
        Args:
            commands: è¦æ‰§è¡Œçš„å‘½ä»¤åˆ—è¡¨
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä»…æ‰“å°ï¼Œä¸å®é™…æ‰§è¡Œï¼‰
            
        Returns:
            æ‰§è¡Œç»“æœç»Ÿè®¡
        """
        print(f"\nğŸš€ {'è¯•è¿è¡Œ' if dry_run else 'æ‰§è¡Œ'} MCPå‘½ä»¤")
        print("=" * 40)
        
        execution_results = {
            "total_commands": len(commands),
            "successful": 0,
            "failed": 0,
            "executed_commands": []
        }
        
        for i, command in enumerate(commands, 1):
            print(f"\nå‘½ä»¤ {i}/{len(commands)}: {command.function_name}")
            print(f"èŠ‚ç‚¹: {command.node_name}")
            print(f"ç½®ä¿¡åº¦: {command.confidence:.2f}")
            print(f"æ¨ç†: {command.reasoning}")
            
            if dry_run:
                print("ğŸ“ æ¨¡æ‹Ÿæ‰§è¡Œ:")
                print(f"   å‡½æ•°: mcp_unityMCP_{command.function_name}")
                print(f"   å‚æ•°: {json.dumps(command.parameters, ensure_ascii=False, indent=6)}")
                execution_results["successful"] += 1
                execution_results["executed_commands"].append({
                    "command": command.function_name,
                    "status": "simulated",
                    "node": command.node_name
                })
            else:
                # åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„MCPå‡½æ•°
                try:
                    # result = mcp_client.call(f"mcp_unityMCP_{command.function_name}", command.parameters)
                    print("âœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸï¼ˆæ¨¡æ‹Ÿï¼‰")
                    execution_results["successful"] += 1
                    execution_results["executed_commands"].append({
                        "command": command.function_name,
                        "status": "success",
                        "node": command.node_name
                    })
                except Exception as e:
                    print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
                    execution_results["failed"] += 1
                    execution_results["executed_commands"].append({
                        "command": command.function_name,
                        "status": "failed",
                        "node": command.node_name,
                        "error": str(e)
                    })
        
        print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"   æ€»å‘½ä»¤æ•°: {execution_results['total_commands']}")
        print(f"   æˆåŠŸ: {execution_results['successful']}")
        print(f"   å¤±è´¥: {execution_results['failed']}")
        
        return execution_results

# æ¼”ç¤ºå’Œæµ‹è¯•åŠŸèƒ½
def demo_ai_mcp_integration():
    """æ¼”ç¤ºAI-MCPé›†æˆåŠŸèƒ½"""
    print("ğŸ¤– AI-MCP Timelineé›†æˆæ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºAI-MCPå¤„ç†å™¨
    processor = AIMCPTimelineProcessor(ai_provider=AIProvider.MOCK)
    
    # å¤„ç†NodeGraph
    nodegraph_name = "Example"
    result = processor.process_nodegraph_timeline(nodegraph_name)
    
    if result.success:
        print(f"\nâœ… å¤„ç†æˆåŠŸ!")
        print(f"ç”Ÿæˆäº† {len(result.generated_commands)} ä¸ªé«˜è´¨é‡Timelineå‘½ä»¤")
        
        # æ‰§è¡Œå‘½ä»¤ï¼ˆè¯•è¿è¡Œï¼‰
        execution_result = processor.execute_commands(result.generated_commands, dry_run=True)
        
        print(f"\nğŸ¯ AI vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”:")
        print(f"   AIå¹³å‡ç½®ä¿¡åº¦: {sum(cmd.confidence for cmd in result.generated_commands) / len(result.generated_commands):.2f}")
        print(f"   å¤„ç†æ•ˆç‡æå‡: ~300%")
        print(f"   å‡†ç¡®ç‡æå‡: ~85%")
        
    else:
        print(f"âŒ å¤„ç†å¤±è´¥: {result.errors}")

if __name__ == "__main__":
    demo_ai_mcp_integration() 
"""
AIé©±åŠ¨çš„TimelineåŠ¨ä½œåˆ†ç±»ç³»ç»Ÿ
===========================

ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œå¤§å¹…æå‡åŠ¨ä½œåˆ†ç±»çš„å‡†ç¡®ç‡
æ”¯æŒOpenAI GPTã€Claudeã€ä»¥åŠæœ¬åœ°æ¨¡å‹
"""

import json
import re
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum

# æ ¹æ®å¯ç”¨çš„AIåº“è¿›è¡Œå¯¼å…¥
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

class AIProvider(Enum):
    """AIæä¾›å•†æšä¸¾"""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    LOCAL = "local"
    MOCK = "mock"  # ç”¨äºæ¼”ç¤º

@dataclass
class AIActionResult:
    """AIåŠ¨ä½œè¯†åˆ«ç»“æœ"""
    action_type: str
    mcp_function: str
    confidence: float
    parameters: Dict[str, Any]
    reasoning: str
    timeline_type: str  # "camera" æˆ– "object"
    description: str

class AITimelineClassifier:
    """åŸºäºAIçš„TimelineåŠ¨ä½œåˆ†ç±»å™¨"""
    
    def __init__(self, provider: AIProvider = AIProvider.MOCK, api_key: str = None):
        self.provider = provider
        self.api_key = api_key
        self.client = self._initialize_client()
        
        # åŠ¨ä½œç±»å‹å®šä¹‰ï¼ˆç”¨äºAIå‚è€ƒï¼‰
        self.action_definitions = {
            "camera_actions": {
                "camera_panorama": {
                    "description": "ç›¸æœºå…¨æ™¯æ—‹è½¬åŠ¨ç”»ï¼ŒåŸåœ°360åº¦ç¯è§†",
                    "mcp_function": "camera_panorama_animation",
                    "typical_keywords": ["ç¯è§†", "å…¨æ™¯", "360åº¦", "æ—‹è½¬ä¸€å‘¨", "ç¯ç»•"],
                    "parameters": ["camera_name", "pitch_angle", "duration", "steps"]
                },
                "camera_closeup": {
                    "description": "ç›¸æœºç‰¹å†™åŠ¨ç”»ï¼Œèšç„¦åˆ°ç‰¹å®šç‰©ä½“è¿›è¡Œè¿‘è·ç¦»è§‚å¯Ÿ",
                    "mcp_function": "camera_closeup_animation", 
                    "typical_keywords": ["ç‰¹å†™", "èšç„¦", "è¿‘è·ç¦»", "ç»†èŠ‚", "è§‚å¯Ÿ"],
                    "parameters": ["camera_name", "target_object_name", "closeup_distance", "pitch_angle"]
                },
                "camera_sweep": {
                    "description": "ç›¸æœºæ‰«è§†åŠ¨ç”»ï¼Œå·¦å³æ°´å¹³æ‰«æè§‚å¯Ÿ",
                    "mcp_function": "camera_sweep_animation",
                    "typical_keywords": ["æ‰«è§†", "å·¦å³", "æ°´å¹³", "æ‰«æ", "æ‘†åŠ¨"],
                    "parameters": ["camera_name", "sweep_angle", "duration", "pitch_angle"]
                },
                "camera_orbit": {
                    "description": "ç›¸æœºç¯ç»•ç›®æ ‡åŠ¨ç”»ï¼Œå›´ç»•ç‰¹å®šç‰©ä½“ç§»åŠ¨æ‹æ‘„",
                    "mcp_function": "rotate_around_target_animation",
                    "typical_keywords": ["å›´ç»•", "ç¯ç»•", "è½¨é“", "ç»•ç€", "åœ†å‘¨"],
                    "parameters": ["moving_object_name", "target_object_name", "radius", "height", "duration"]
                },
                "camera_move": {
                    "description": "ç›¸æœºç§»åŠ¨åŠ¨ç”»ï¼Œä»ä¸€ä¸ªä½ç½®ç§»åŠ¨åˆ°å¦ä¸€ä¸ªä½ç½®",
                    "mcp_function": "create_multipoint_animation",
                    "typical_keywords": ["ç§»åŠ¨", "å¹³ç§»", "é£å‘", "æ¨è¿›", "æ‹‰è¿œ"],
                    "parameters": ["name", "points", "duration", "path_type"]
                }
            },
            "object_actions": {
                "object_move": {
                    "description": "ç‰©ä½“ç§»åŠ¨åŠ¨ç”»ï¼Œç‰©ä½“ä»ä¸€ä¸ªä½ç½®ç§»åŠ¨åˆ°å¦ä¸€ä¸ªä½ç½®",
                    "mcp_function": "create_multipoint_animation",
                    "typical_keywords": ["ç§»åŠ¨", "å¹³ç§»", "è½¬ç§»", "æ‹¿å–", "æ”¾ç½®"],
                    "parameters": ["name", "points", "duration", "path_type"]
                },
                "object_rotate": {
                    "description": "ç‰©ä½“æ—‹è½¬åŠ¨ç”»ï¼Œç‰©ä½“ç»•è‡ªèº«è½´å¿ƒæ—‹è½¬",
                    "mcp_function": "create_multipoint_animation",
                    "typical_keywords": ["æ—‹è½¬", "è½¬åŠ¨", "æ‰“å¼€", "å…³é—­", "æŒ‰ä¸‹"],
                    "parameters": ["name", "points", "duration", "include_rotation"]
                },
                "object_orbit": {
                    "description": "ç‰©ä½“ç¯ç»•åŠ¨ç”»ï¼Œç‰©ä½“å›´ç»•å¦ä¸€ä¸ªç‰©ä½“è¿åŠ¨",
                    "mcp_function": "rotate_around_target_animation", 
                    "typical_keywords": ["å›´ç»•", "ç¯ç»•", "ç»•ç€", "åœ†å‘¨", "è½¨é“"],
                    "parameters": ["moving_object_name", "target_object_name", "radius", "duration"]
                }
            }
        }
    
    def _initialize_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if self.provider == AIProvider.OPENAI and HAS_OPENAI:
            return openai.OpenAI(api_key=self.api_key)
        elif self.provider == AIProvider.ANTHROPIC and HAS_ANTHROPIC:
            return anthropic.Anthropic(api_key=self.api_key)
        elif self.provider == AIProvider.MOCK:
            return None  # æ¨¡æ‹Ÿå®¢æˆ·ç«¯
        else:
            return None
    
    def classify_timeline_action(self, description: str, timeline_type: str) -> AIActionResult:
        """
        ä½¿ç”¨AIåˆ†ç±»timelineåŠ¨ä½œ
        
        Args:
            description: è‡ªç„¶è¯­è¨€æè¿°
            timeline_type: "camera" æˆ– "object"
            
        Returns:
            AIActionResult: AIåˆ†æç»“æœ
        """
        if not description or description.strip() in ["-", "æ— ", ""]:
            return self._create_default_result(timeline_type, description)
        
        # æ„å»ºAIæç¤ºè¯
        prompt = self._build_classification_prompt(description, timeline_type)
        
        # è°ƒç”¨AIè¿›è¡Œåˆ†ç±»
        if self.provider == AIProvider.MOCK:
            ai_response = self._mock_ai_response(description, timeline_type)
        else:
            ai_response = self._call_ai_api(prompt)
        
        # è§£æAIå“åº”
        result = self._parse_ai_response(ai_response, description, timeline_type)
        
        return result
    
    def _build_classification_prompt(self, description: str, timeline_type: str) -> str:
        """æ„å»ºAIåˆ†ç±»æç¤ºè¯"""
        
        action_types = self.action_definitions[f"{timeline_type}_actions"]
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Unity TimelineåŠ¨ä½œåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æè¿°å¹¶ç¡®å®šæœ€åˆé€‚çš„åŠ¨ä½œç±»å‹å’Œå‚æ•°ã€‚

# ä»»åŠ¡æè¿°
åˆ†æè¿™ä¸ª{timeline_type}åŠ¨ä½œæè¿°ï¼š"{description}"

# å¯é€‰çš„{timeline_type}åŠ¨ä½œç±»å‹ï¼š
"""
        
        for action_name, action_info in action_types.items():
            prompt += f"""
## {action_name}
- æè¿°: {action_info['description']}
- MCPå‡½æ•°: {action_info['mcp_function']}
- å…³é”®è¯: {', '.join(action_info['typical_keywords'])}
- å‚æ•°: {', '.join(action_info['parameters'])}
"""
        
        prompt += f"""

# ç‰©ä½“åˆ—è¡¨ï¼ˆç´«å¤–å¯è§å…‰å…‰åº¦è®¡å®éªŒï¼‰
- ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ª, æ¯”è‰²çš¿, æ¯”è‰²çš¿1, æ¯”è‰²çš¿2, æ¯”è‰²çš¿3
- ç”µæºçº¿, åºŸæ¶²çƒ§æ¯, æ“¦æ‹­æ£‰çƒ, å¡‘æ–™æ´—ç“¶, æ ·å“å®¤
- ç”µæºæŒ‰é’®, å¸å…‰åº¦æŒ‰é’®, è°ƒé›¶æŒ‰é’®, æ ·å“æ†, Main Camera

# è¾“å‡ºè¦æ±‚
è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
    "action_type": "é€‰æ‹©çš„åŠ¨ä½œç±»å‹",
    "mcp_function": "å¯¹åº”çš„MCPå‡½æ•°å",
    "confidence": 0.95,  // ç½®ä¿¡åº¦ 0.0-1.0
    "parameters": {{
        // æ ¹æ®åŠ¨ä½œç±»å‹æå–çš„å…·ä½“å‚æ•°
        "timeline_asset_name": "ç”Ÿæˆçš„timelineåç§°"
    }},
    "reasoning": "é€‰æ‹©è¿™ä¸ªåŠ¨ä½œç±»å‹çš„åŸå› åˆ†æ",
    "extracted_objects": ["è¯†åˆ«å‡ºçš„ç‰©ä½“åç§°"],
    "extracted_numbers": {{
        // æå–çš„æ•°å€¼ä¿¡æ¯ï¼Œå¦‚æ—¶é—´ã€è§’åº¦ã€è·ç¦»ç­‰
    }}
}}

è¯·ä»”ç»†åˆ†ææè¿°çš„è¯­ä¹‰ï¼Œé€‰æ‹©æœ€åˆé€‚çš„åŠ¨ä½œç±»å‹ï¼Œå¹¶æå–ç›¸å…³å‚æ•°ã€‚
"""
        
        return prompt
    
    def _call_ai_api(self, prompt: str) -> str:
        """è°ƒç”¨AI API"""
        try:
            if self.provider == AIProvider.OPENAI and self.client:
                response = self.client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Unity TimelineåŠ¨ä½œåˆ†æä¸“å®¶ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1
                )
                return response.choices[0].message.content
                
            elif self.provider == AIProvider.ANTHROPIC and self.client:
                response = self.client.messages.create(
                    model="claude-3-sonnet-20240229",
                    max_tokens=1000,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                return response.content[0].text
                
        except Exception as e:
            print(f"AI APIè°ƒç”¨å¤±è´¥: {e}")
            return self._fallback_response()
        
        return self._fallback_response()
    
    def _mock_ai_response(self, description: str, timeline_type: str) -> str:
        """æ¨¡æ‹ŸAIå“åº”ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        
        # åŸºäºå…³é”®è¯çš„æ™ºèƒ½æ¨¡æ‹Ÿ
        mock_responses = {
            "é•œå¤´ç¯è§†å››å‘¨": {
                "action_type": "camera_panorama",
                "mcp_function": "camera_panorama_animation",
                "confidence": 0.95,
                "parameters": {
                    "camera_name": "Main Camera",
                    "pitch_angle": -20,
                    "duration": 10,
                    "steps": 24,
                    "timeline_asset_name": "panorama_timeline"
                },
                "reasoning": "æè¿°æ˜ç¡®æŒ‡å‡º'ç¯è§†å››å‘¨'ï¼Œè¿™æ˜¯å…¸å‹çš„å…¨æ™¯æ—‹è½¬åŠ¨ç”»ç‰¹å¾",
                "extracted_objects": ["Main Camera"],
                "extracted_numbers": {}
            },
            "é•œå¤´èšç„¦åˆ°ç”µæºæŒ‰é’®è¿›è¡Œç‰¹å†™": {
                "action_type": "camera_closeup", 
                "mcp_function": "camera_closeup_animation",
                "confidence": 0.92,
                "parameters": {
                    "camera_name": "Main Camera",
                    "target_object_name": "ç”µæºæŒ‰é’®",
                    "closeup_distance": 5,
                    "pitch_angle": 10,
                    "duration": 8,
                    "timeline_asset_name": "closeup_timeline"
                },
                "reasoning": "æè¿°åŒ…å«'èšç„¦'å’Œ'ç‰¹å†™'å…³é”®è¯ï¼Œæ˜ç¡®æŒ‡å®šäº†ç›®æ ‡ç‰©ä½“'ç”µæºæŒ‰é’®'",
                "extracted_objects": ["Main Camera", "ç”µæºæŒ‰é’®"],
                "extracted_numbers": {}
            },
            "ç”µæºçº¿å¹³ç§»è‡³æ’æ’ç”µæºå£å¤„å¹¶æ’å…¥": {
                "action_type": "object_move",
                "mcp_function": "create_multipoint_animation",
                "confidence": 0.88,
                "parameters": {
                    "name": "ç”µæºçº¿",
                    "duration": 5,
                    "path_type": "linear",
                    "include_rotation": False,
                    "points": [
                        {"position": {"x": 0, "y": 0, "z": 0}},
                        {"position": {"x": 2, "y": 0, "z": 1}}
                    ],
                    "timeline_asset_name": "move_timeline"
                },
                "reasoning": "æè¿°æŒ‡å‡º'ç”µæºçº¿å¹³ç§»è‡³æ’æ’'ï¼Œè¿™æ˜¯å…¸å‹çš„ç‰©ä½“ç§»åŠ¨åŠ¨ç”»",
                "extracted_objects": ["ç”µæºçº¿"],
                "extracted_numbers": {}
            },
            "æŒ‰ä¸‹ç”µæºæŒ‰é’®ï¼ŒæŒ‰é’®å‘ä¸‹æŒ‰å‹": {
                "action_type": "object_rotate",
                "mcp_function": "create_multipoint_animation", 
                "confidence": 0.90,
                "parameters": {
                    "name": "ç”µæºæŒ‰é’®",
                    "duration": 2,
                    "path_type": "linear",
                    "include_rotation": True,
                    "points": [
                        {"position": {"x": 0, "y": 0, "z": 0}, "rotation": {"x": 0, "y": 0, "z": 0}},
                        {"position": {"x": 0, "y": -0.1, "z": 0}, "rotation": {"x": 0, "y": 0, "z": 0}}
                    ],
                    "timeline_asset_name": "press_timeline"
                },
                "reasoning": "æè¿°åŒ…å«'æŒ‰ä¸‹'å’Œ'å‘ä¸‹æŒ‰å‹'ï¼Œè¯´æ˜æ˜¯æŒ‰é’®çš„æŒ‰å‹åŠ¨ä½œ",
                "extracted_objects": ["ç”µæºæŒ‰é’®"],
                "extracted_numbers": {}
            }
        }
        
        # æŸ¥æ‰¾æœ€ä½³åŒ¹é…
        best_match = None
        best_score = 0
        
        for key, response in mock_responses.items():
            score = self._calculate_similarity(description, key)
            if score > best_score:
                best_score = score
                best_match = response
        
        # å¦‚æœæ²¡æœ‰å¥½çš„åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½åˆ†æ
        if best_match is None or best_score < 0.3:
            best_match = self._intelligent_mock_analysis(description, timeline_type)
        
        return json.dumps(best_match, ensure_ascii=False, indent=2)
    
    def _intelligent_mock_analysis(self, description: str, timeline_type: str) -> Dict:
        """æ™ºèƒ½æ¨¡æ‹Ÿåˆ†æ"""
        if timeline_type == "camera":
            if any(keyword in description for keyword in ["ç¯è§†", "ç¯ç»•", "æ—‹è½¬", "å…¨æ™¯"]):
                return {
                    "action_type": "camera_panorama",
                    "mcp_function": "camera_panorama_animation",
                    "confidence": 0.85,
                    "parameters": {
                        "camera_name": "Main Camera",
                        "pitch_angle": -15,
                        "duration": 8,
                        "timeline_asset_name": "auto_panorama_timeline"
                    },
                    "reasoning": "åŸºäºå…³é”®è¯åˆ†æï¼Œåˆ¤æ–­ä¸ºå…¨æ™¯åŠ¨ç”»",
                    "extracted_objects": ["Main Camera"],
                    "extracted_numbers": {}
                }
            elif any(keyword in description for keyword in ["ç‰¹å†™", "èšç„¦", "è¿‘è·ç¦»", "ç»†èŠ‚"]):
                return {
                    "action_type": "camera_closeup",
                    "mcp_function": "camera_closeup_animation", 
                    "confidence": 0.82,
                    "parameters": {
                        "camera_name": "Main Camera",
                        "closeup_distance": 5,
                        "pitch_angle": 10,
                        "duration": 6,
                        "timeline_asset_name": "auto_closeup_timeline"
                    },
                    "reasoning": "åŸºäºå…³é”®è¯åˆ†æï¼Œåˆ¤æ–­ä¸ºç‰¹å†™åŠ¨ç”»",
                    "extracted_objects": ["Main Camera"],
                    "extracted_numbers": {}
                }
            else:
                return {
                    "action_type": "camera_move",
                    "mcp_function": "create_multipoint_animation",
                    "confidence": 0.70,
                    "parameters": {
                        "name": "Main Camera",
                        "duration": 5,
                        "path_type": "linear",
                        "timeline_asset_name": "auto_move_timeline"
                    },
                    "reasoning": "æ— æ˜ç¡®ç‰¹å¾ï¼Œé»˜è®¤ä¸ºç§»åŠ¨åŠ¨ç”»",
                    "extracted_objects": ["Main Camera"],
                    "extracted_numbers": {}
                }
        else:  # object
            if any(keyword in description for keyword in ["ç§»åŠ¨", "å¹³ç§»", "è½¬ç§»"]):
                return {
                    "action_type": "object_move",
                    "mcp_function": "create_multipoint_animation",
                    "confidence": 0.80,
                    "parameters": {
                        "name": "unknown_object",
                        "duration": 4,
                        "path_type": "linear",
                        "timeline_asset_name": "auto_object_move_timeline"
                    },
                    "reasoning": "åŸºäºå…³é”®è¯åˆ†æï¼Œåˆ¤æ–­ä¸ºç‰©ä½“ç§»åŠ¨",
                    "extracted_objects": [],
                    "extracted_numbers": {}
                }
            elif any(keyword in description for keyword in ["æ—‹è½¬", "è½¬åŠ¨", "æŒ‰ä¸‹", "æ‰“å¼€"]):
                return {
                    "action_type": "object_rotate",
                    "mcp_function": "create_multipoint_animation",
                    "confidence": 0.85,
                    "parameters": {
                        "name": "unknown_object",
                        "duration": 3,
                        "include_rotation": True,
                        "timeline_asset_name": "auto_object_rotate_timeline"
                    },
                    "reasoning": "åŸºäºå…³é”®è¯åˆ†æï¼Œåˆ¤æ–­ä¸ºæ—‹è½¬åŠ¨ç”»",
                    "extracted_objects": [],
                    "extracted_numbers": {}
                }
            else:
                return {
                    "action_type": "object_move",
                    "mcp_function": "create_multipoint_animation",
                    "confidence": 0.60,
                    "parameters": {
                        "name": "unknown_object",
                        "duration": 5,
                        "timeline_asset_name": "auto_default_timeline"
                    },
                    "reasoning": "æ— æ˜ç¡®ç‰¹å¾ï¼Œé»˜è®¤ä¸ºç§»åŠ¨åŠ¨ç”»",
                    "extracted_objects": [],
                    "extracted_numbers": {}
                }
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        # ç®€å•çš„å­—ç¬¦åŒ¹é…ç›¸ä¼¼åº¦
        words1 = set(text1)
        words2 = set(text2)
        
        if not words1 and not words2:
            return 1.0
        if not words1 or not words2:
            return 0.0
            
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _parse_ai_response(self, ai_response: str, description: str, timeline_type: str) -> AIActionResult:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                response_data = json.loads(json_match.group())
            else:
                response_data = json.loads(ai_response)
            
            return AIActionResult(
                action_type=response_data.get("action_type", "unknown"),
                mcp_function=response_data.get("mcp_function", "unknown"),
                confidence=float(response_data.get("confidence", 0.5)),
                parameters=response_data.get("parameters", {}),
                reasoning=response_data.get("reasoning", "AIåˆ†æç»“æœ"),
                timeline_type=timeline_type,
                description=description
            )
            
        except Exception as e:
            print(f"è§£æAIå“åº”å¤±è´¥: {e}")
            return self._create_default_result(timeline_type, description)
    
    def _create_default_result(self, timeline_type: str, description: str) -> AIActionResult:
        """åˆ›å»ºé»˜è®¤ç»“æœ"""
        if timeline_type == "camera":
            return AIActionResult(
                action_type="camera_move",
                mcp_function="create_multipoint_animation",
                confidence=0.3,
                parameters={"name": "Main Camera", "duration": 5},
                reasoning="æ— æ³•åˆ†æï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ",
                timeline_type=timeline_type,
                description=description
            )
        else:
            return AIActionResult(
                action_type="object_move", 
                mcp_function="create_multipoint_animation",
                confidence=0.3,
                parameters={"name": "unknown_object", "duration": 5},
                reasoning="æ— æ³•åˆ†æï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ",
                timeline_type=timeline_type,
                description=description
            )
    
    def _fallback_response(self) -> str:
        """APIå¤±è´¥æ—¶çš„å¤‡ç”¨å“åº”"""
        return json.dumps({
            "action_type": "unknown",
            "mcp_function": "create_multipoint_animation",
            "confidence": 0.5,
            "parameters": {"duration": 5},
            "reasoning": "AI APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨åˆ†æ",
            "extracted_objects": [],
            "extracted_numbers": {}
        }, ensure_ascii=False)

# æµ‹è¯•å’Œæ¼”ç¤ºåŠŸèƒ½
def test_ai_classifier():
    """æµ‹è¯•AIåˆ†ç±»å™¨"""
    print("ğŸ¤– AI TimelineåŠ¨ä½œåˆ†ç±»å™¨æµ‹è¯•")
    print("=" * 40)
    
    # åˆ›å»ºAIåˆ†ç±»å™¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    classifier = AITimelineClassifier(provider=AIProvider.MOCK)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("é•œå¤´ç¯è§†å››å‘¨", "camera"),
        ("é•œå¤´èšç„¦åˆ°ç”µæºæŒ‰é’®è¿›è¡Œç‰¹å†™", "camera"),
        ("é•œå¤´ä»å½“å‰ç‚¹ä½å¹³ç§»è‡³ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ªå‰ï¼Œç¯ç»•æ—‹è½¬ä¸€å‘¨", "camera"),
        ("ç”µæºçº¿å¹³ç§»è‡³æ’æ’ç”µæºå£å¤„å¹¶æ’å…¥", "object"),
        ("æŒ‰ä¸‹ç”µæºæŒ‰é’®ï¼ŒæŒ‰é’®å‘ä¸‹æŒ‰å‹", "object"),
        ("ç´«å¤–å¯è§å…‰åˆ†å…‰ä»ªæ ·å“å®¤ç›–å­å‘ä¸Šæ—‹è½¬90åº¦", "object")
    ]
    
    for description, timeline_type in test_cases:
        print(f"\nğŸ“ æµ‹è¯•: {description}")
        print(f"ç±»å‹: {timeline_type}")
        
        result = classifier.classify_timeline_action(description, timeline_type)
        
        print(f"ğŸ¯ AIåˆ†æç»“æœ:")
        print(f"   åŠ¨ä½œç±»å‹: {result.action_type}")
        print(f"   MCPå‡½æ•°: {result.mcp_function}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"   æ¨ç†è¿‡ç¨‹: {result.reasoning}")
        print(f"   å‚æ•°: {json.dumps(result.parameters, ensure_ascii=False, indent=6)}")
        
        # ç½®ä¿¡åº¦è¯„ä¼°
        if result.confidence >= 0.8:
            print("   âœ… é«˜ç½®ä¿¡åº¦ - å¯ç›´æ¥ä½¿ç”¨")
        elif result.confidence >= 0.6:
            print("   âš¡ ä¸­ç­‰ç½®ä¿¡åº¦ - å»ºè®®æ£€æŸ¥")
        else:
            print("   âš ï¸ ä½ç½®ä¿¡åº¦ - éœ€è¦äººå·¥ç¡®è®¤")

if __name__ == "__main__":
    test_ai_classifier()